
Saturday May 13th 2017
======================

    8:27AM - Start work.

        Going to have a crack at the yojimbo teardown in a branch: "experimental"

        ...



Friday May 12th 2017
====================

    10:18PM - What are the next tasks?

        I need to get an RTT estimate working.

        Packet loss estimate.

        Jitter estimate.

        Start here, then once these are working, research the congestion avoidance algorithm to implement.

        To implement packet loss estimate I simply need to check packets at 50% in the past in the send packet sequence buffer (eg. walk old to new).

        To implement RTT estimate, I need to track the time of send, and compare the time when the packet is acked to get the instantaneous RTT est, then smooth this.

        How to best implement the jitter estimate? I don't think it's possible, because it requires a timestamp in each packet, so jitter estimate must be *above* reliable.io.

        Alternatively, packet send rate is assumed to be constant, then we can have a jitter estimate, but this can't be required that the packet send rate is fixed at this level, so I think we might want to leave jitter buffer to a higher level API (eg. one that can include timestamps per-packet).

        Stuff to read about BBR:

            http://queue.acm.org/detail.cfm?id=3022184

            https://www.ietf.org/proceedings/97/slides/slides-97-iccrg-bbr-congestion-control-02.pdf

            https://www.ietf.org/proceedings/98/slides/slides-98-iccrg-an-update-on-bbr-congestion-control-00.pdf

            https://blog.acolyer.org/2017/03/31/bbr-congestion-based-congestion-control/        <---- this one is really good.

            https://www.ietf.org/proceedings/98/slides/slides-98-iccrg-an-update-on-bbr-congestion-control-00.pdf

            https://github.com/google/bbr

            https://lwn.net/Articles/701165/

            http://www.thequilt.net/wp-content/uploads/BBR-TCP-Opportunities.pdf

            http://blog.cerowrt.org/post/bbrs_basic_beauty/

            https://news.ycombinator.com/item?id=13087574

            https://patchwork.ozlabs.org/patch/671069/

            https://blog.jie.today/2016/12/09/using-bbr-congestion-control-to-improve-connection-speed/

            http://www.dslreports.com/forum/r31197838-Google-s-BBR-Congestion-Control-Algorithm

            http://news.softpedia.com/news/google-creates-new-algorithm-for-handling-tcp-traffic-congestion-control-508398.shtml

            https://en.wikipedia.org/wiki/TCP_congestion_control

            http://etherealmind.com/research-bbr-congestion-based-congestion-control-acm-queue/

        Hmmm. I could derive jitter from the ack time variance... but this would tend to overestimate it, I think? eg. measure jitter in both directions?

        Some good stuff on TCP RTT estimates:

            https://www.quora.com/How-does-TCP-round-trip-time-RTT-estimation-work-How-different-is-the-implementation-across-operating-systems

            https://networkengineering.stackexchange.com/questions/10587/initial-estimated-round-trip-time-in-the-rtt-formula

            https://en.wikipedia.org/wiki/Round-trip_delay_time

            https://www.usenix.org/legacy/publications/library/proceedings/mobisys03/tech/full_papers/dunkels/dunkels_html/node18.html

            http://web.opalsoft.net/qos/default.php?p=tcp-10

            http://www.mathcs.emory.edu/~cheung/Courses/455/Syllabus/7-transport/timeout.html

            http://blog.catchpoint.com/2014/04/29/understanding-rtt-impact-on-tcp-retransmissions/

            https://tools.ietf.org/html/rfc6323

        More on jitter:

            https://www.slac.stanford.edu/comp/net/wan-mon/oneway-jitter.html

            https://tools.ietf.org/html/rfc3393

            http://www.cyberjournals.com/Papers/Aug2011/01.pdf

            http://link.springer.com/chapter/10.1007/978-3-642-13861-4_15

            https://www.researchgate.net/publication/224645037_Available_Bandwidth_Estimation_via_One-Way_Delay_Jitter_and_Queuing_Delay_Propagation_Model

    11:37PM - Stop research for tonight. Will continue reading through these papers and links tomorrow.

        Branching off yojimbo to a private branch where I can do some work for Remedy. Probably best to bring across the client/server interface first, because much of the lower-level implmentations are complicated and tied together.

        Starting with this: "yojimbo-private" in my branch for now, until I am comfortable to go public with this work.

    12:16PM - Stop work for tonight. Continue tomorrow morning.



Friday May 5th, 2017
====================

    8:02AM - Start work.

        Moving forward with the processing of fragments now. Need to implement logic to actually copy the fragment data in.

        Tricky logic for first, and last fragment (also, they can be the same, single fragment, if fragment_above is smaller than fragment size...)

    8:45AM - Almost working.

        There is a small logic error where the first fragment is getting rejected because it doesn't have the expected size.

        Need to debug and fix the fragment header read function to fix this.

        Also, to help track down, I'm really missing logs, need to bring the debug logs from netcode.io back in, and turn them on in the soak test.

        Once this is done, extend the soak test to create packets with 16 bit sequence in first 2 bytes, then rest of packet as a function of that sequence #, this will allow verification of both packet length and contents, which is necessary to prove that the fragmentation and reassembly is working correctly.

        Once all this is completed, packet fragmentation and reassembly is complete.

    8:47AM - Break for breakfast.

        *** BREAK ***

    9:04AM - Quickly trying to fix fragment 0 processing.

        Just a logic bug on fragment id pointer not being dereferenced.

        Seems to be processing packets now.

    9:09AM - Stop work.

        *** BREAK ***

    12:29PM - Re-adding logging now. I need logs to be able to identify that the system is working correctly.

        Do I need the same log levels? Not really. Just debug is really necessary for now.

        Added a config name per-endpoint, so multiple endpoints can be distinguished in the log.

    1:18PM - Added a bunch of logs. Looking great.

        Continuing with logs. Trying to get everything in under the logs rather than printf.

    1:35PM - Stop work.

        *** LUNCH ***

    2:07PM - Back at work.

        Continuing with logs.

    2:11PM - Logs completed.

        Now I need to hook up the packet size, and the packet contents so they can be verified.

        Adding a function to generate a packet, and another to verify a packet.

    2:53PM - Finished adding code to generate packet size and contents plus validate fn.

        Validation hits. It seems to be because the first two bytes of the packet aren't valid, for fragmented and reassembled packets.

        Something is definitely chewing up the packet contents for fragmented and reassembled packets. Need to debug to see what's going on.

    2:54PM - Stop work.

         *** BREAK ***

    4:23PM - Debugging fragment data.

        Found it. Needed to adjust fragment 0 to skip packet header data.

        Soak test now runs flawlessly. The sequence # and length of packet is correct, next step is to verify packet contents as well.

        Doing this now.

    4:36PM - Done.

        Now I have some small cleanup to do:

            1. Don't call process packet if the sequence # is stale, need to add supporting function to check if insert would fail.

            2. Add a unit test to verify that regular packets get through (derive from soak test)

            3. Add a unit test to verify fragmented packets get through (derive from soak test)

            4. Extend soak test with a check like macro, so it validates in release build.

            5. Run valgrind over soak test, make sure no memory leaks have snuck in.

            6. Implement a fuzz test, creates an endpoint and feeds it truly random packet data forever. Make sure it can handle it without crashing. eg. "pm fuzz".

    4:42PM - Adding check macro to soak test.        

        Done.

        Ran valgrind. No leaks.

        Added "reliable_sequence_buffer_test_insert" to check if sequence # is stale before calling process packet fn ptr.

        Now I want to implement the fuzz test. This will be interesting. Setup an endpoint and pump it, and try to feed it random crap, goal is for it to not crash.

        Implementing fuzz.c now...

        Implemented. Found an assert. Fuzz test passes now.

    5:12PM - What is left to do?

        Add unit test for regular packet, fragmented packet w. checks for packet length and content.

        That's it. Taking a break for the moment. Will get to this later today.

        After this, all that remains is to implement the QoS.

    5:17PM - Taking a break.

        *** BREAK ***

    6:55PM - Finishing up unit tests before dinner.

        Extended function pointers to transmit and process packet to take uint16_t sequence #. 

        Reasoning is that if the processing packet function needs the sequence #, this is the only way it's going to get it.

        For example, yojimbo will want to know the sequence # for the message system when processing a packet.

        It's probably not needed on transmit, but for consistency, it was added there. Plus might be good for logging.

    7:04PM - Next task is to extend unit test to generate a packet and verify it. Do this for existing tests, before extending to fragmented packets.

        *** BREAK ***

    9:59PM - Time to work on the unit test extension.

        Added test and made sure it covers both regular and fragmented packets.

        This is enough testing for the fragmentation and reassembly. It works.

        The remaining work is as follows:

            1. Implemnet the RTT and packet loss estimates

            2. Implement the congestion avoidance notification

        Study the newer congestion avoidance technique to come up with an implementation.

        Don't discard packets when congested, but flag congestion up to the user layer.

    10:38PM - Stopping work for tonight.

        *** STOP WORK ***




Thursday May 4th, 2017
======================

    11:08AM - First thing that needs to be done today is to add the sequence # in front of fragments, then fix the annoying bit with the packet header in first fragment.

        Starting this now. Important to get this sorted out before starting on fragment receive processing.

        Added the first fix to this to soak, that verifies it craps out with a 16k packet, with 1k fragments, 16 max. 

        Now to fix this...

    11:23AM - Yes. The work is finished.

        The fragments packets are now not guaranteed to be a max size, the sequence # is added in front of each fragment, and the 0 fragment has the variable length packet header in front of it.

        Next step now is to implement the functionality for processing fragment packets. I think this is basically just a sequence buffer.

    11:25AM - Now thinking about how to best implement the packet reassembly.

        It's clear that it is a sequence buffer, and each sequence buffer entry needs to store:

            a) the packet header info
            b) the # of fragments in the packet
            c) the # of fragments received so far
            d) pointer to packet data (should be one big block, allocated to worst case size for # of fragments known)
            e) the total packet size (only known when n-1th fragment is received)

        This way there is no need for a copy on process, since the packet will be fully formed ready to pass to process (intact with packet header).

    11:49AM - Time for a break.

        *** BREAK ***

    2:02PM - Back to work.

        Time to sketch out the data structure for fragment reassembly.

        I think that disabling the packet header optimization will make the code simpler, so I'm going to do that for large fragment packets.

        eg. pad zeros to the max packet header bytes. This way it's a known size. Doing this now. Done.

        Now I need to sketch out the data structure for the reassembly sequence buffer.

        Sketched out. Backflipped on the packet header, I can handle it being variable length now. I need to call the fn. to parse it anyway.

        Just need to make sure some data is reserved at the front of the packet data for worst case packet header. Easy.

    2:26PM - Moving on to implementation. 

    3:13PM - Good progress with implementation.

        To efficiently clean up and free old packet data, I need to add a callback functor to the insert, so when it clears entries, it can call the cleanup functor on them.

        This needs to be done before going any further, because it's nothing but a huge set of memory leaks right now.

        Adding this now.

    3:34PM - Added the insert with cleanup. It seems to be working well.

        To make sure I'm not leaking memory, go ahead with porting across the valgrind test from netcode.io

        Done. Fixing some stuff that linux gcc doesn't like when compiling, eg. for (int i ...)

    3:43PM - Some leaks found.

        Debugging... need to get this leak free before I move forward any further.

    3:52PM - Leaks are fixed.

        Good stuff.

        What's the next step? I think it is bringing across the code that performs validation of fragments when they are received.

    4:12PM - Added code to parse the packet header in fragment 0, so I can know fragment size, plus code to ignore fragments that are BS.

    4:21PM - Continued porting across code. Looking good.

        Have now sketched out everything up to reassembly and log ready to process.

        Some more work required to actually store the fragment data.

        Good progress on reassembly. Time for a break.

    4:23PM - Taking a break.

        *** BREAK ***

    8:49PM - Continuing work on reassembly

        Refactored code to read fragment header etc. into its own function for early out.

        Seems a lot cleaner. Next step is to actually stash the fragment data and process the reassembledpacket.

    9:40PM - Stopping work for today.

        *** STOP WORK ***



Wednesday May 3rd, 2017
=======================

    9:42PM - Starting work.

        Today I want to get the packet fragmentation and reassembly system implemented and working.

        First step is to bring across the example code from the article on fragmentation.

        Also, thinking about protocol specs, yes it is totally OK to have a maximum of 256 fragments, because of packet loss amplification, you would never want to send that many fragments for a packet anyway.

        Getting started with this now...

        Brought across code. I see the packet format now. Starting with the config to determine when to split apart packets.

        This requires config that specifies the maximum packet size (raw payload). Since the header is variable, it's better to do it that way vs. promising "this is the maximum packet size I will ever generate". Simpler.

    10:11AM - Adding config to support packet fragmentation and re-assembly.

    10:39AM - Added basic support for fragmentation and re-assembly at the config level.

        When packets are sent the max packet size is checked, and different codepaths are run for regular packets vs. packets that need to be split up.

    10:41AM - Now I need to add config to control how the fragmentation is performed.

        This should include maximum # of fragments, fragment size and so on. These should be ints, but validated to be in correct range according to fragment packet header bits.

        Added.

    10:58AM - Had a super cool idea for the prefix byte. 

        Low bit can be the fragment bit. 

        Next 4 bits can be used to indicate when bytes of the ack_bits are all 1s. This is common, so would save a lot of bandwidth.

        I should implement this now, before I go further into the fragmentation and re-assembly.

        Should probably turn this into a function, because I'll need to call it for regular packets in one place, and for fragmented packets (post-reassembly) in another.

        I can also consider some optimization for the ack # relative to sequence, eg. the common case is that it is quite close, so I could set one bit if close, then only send it as a byte (or less, if that other byte is used for something).

    11:03AM - Moving forward with more advanced packet structure.

    11:25AM - Implemented write packet header function.

        Added optimization for the ack_bits, plus another optimization reducing sequence # to one byte.

        This is *probably* enough optimization. It's not *OPTIMAL*. But it's a reasonable optimization, without dropping to a bitpacker.

    11:28AM - Now I need to get the read packet header function implemented, and verify that tests pass.

        I should probably also implement a soak test, just to make sure I've got stability and correct performance across the sequence # wrap around.

        Getting started with the read packet header.

    12:13PM - Read packet header completed.

        Back to basics and unit testing the read/write packet header to make sure it works as expected before trying to hook it up.

    12:53PM - Finished a bunch of packet header tests.

        Found and fixed a BUNCH of bugs. Wow. Good call.

        Next I need to hook this up to the send. Checking in work so far.

    12:55PM - Lunch break.

        *** LUNCH ***

    1:22PM - Back to work on integrating the new packet header stuff.

        Once it's integrated and all tests pass, implement soak test.

        Integrating now...

    1:43PM - Done.

        Checking it work then implementing soak test.

    2:03PM - Soak framework is setup.

        Now implementing payload. Just derive it from one of the test acks, but without the checking.

        For the soak to look really good, I need to have some logs added. Ignore for the moment.

    2:12PM - Basic soak test runs.

        Decided I don't need logs for reliable. It's too low level. Logs would be too frequent to turn on for anything other than debugging.

        Adding soak logs.

    2:18PM - Soak test is working as expected.

        It doesn't do much yet, but once packet fragmentation and re-assembly is implemented, it will do a bunch more work during soak.

        Now that the packet header is implemented, the next logical thing to work on is to go back to the fragmentation and re-assembly.

        No point starting this right now, it's time for a break.

    2:19PM - Taking a break.

        *** BREAK ***

    4:11PM - Time to start implementing the packet fragmentation side.

        To do this start with the packet write. It should be reasonably straightforward. It's the processing of packet fragments and reconstructing that is tricky.

    4:52PM - First pass implemented fragment write. Reasonably straightforward.

        I think I need to implement a function to set defaults for config. As I add new stuff to the config, it's easy to fail to update old configs.

        The max packet size is a bad name, unless it's an actual maximum. There needs to be another setting that specifies packet size above which to split into fragments.

        Should it just always be the fragment size? If fragment size is negative, then disable fragmentation and reassembly. Otherwise, split apart packets larger than fragment size?

        I think it's more flexible if the max packet size before fragmentation is separate. Think this through on the bike ride home.

    5:02PM - Taking a break for bike ride.

        *** BREAK ***

    6:24PM - OK. Next is to fix the max packet before fragment.

        Plus the default config.

    7:04PM - Implemented the default config.

        Fixed some bugs in packet fragmentation on send.

        Added logic to handle max packet size on send, receive, eg. too large.

        Next thing to do is to add counters when packets are too large to send, receive, then implement receive processing for fragment packets.

        Adding the counters now. Done.

    7:16PM - Taking break for dinner.

        *** DINNER ***

    7:37PM - Back at work on the fragmentation.

        What data structures do I need for the packet fragment receive processing?

        Look at existing sample code.

        Some things need to be done before moving forward:

        1. The packet fragments need to identify which packet sequence # they belong to (16 bit seq #)

        2. I don't like the config needing to be aware of the header size for max packet size. it should be done under the covers.

    8:01PM - Stopping work for today.

        *** STOP WORK ***



Tuesday May 2nd, 2017
=====================

    9:50AM - Starting work.

        Continuing with endpoint work.

        Extended reliable configuration include void* context pointer. This will allow it to be used from C++.

        Now I need to get an array of acks working. This way I can implement tests that check the set of acks that work.

        Allocated and freed ack array.

        Added interface to get acks, clear ack array (avoids copy).

        Setup code to add acks to ack array.

    10:20AM - Finished work for morning.

        *** BREAK ***

    2:40PM - Back to work.

        It's time to bring across some tests for the ack system.

        Need to setup a framework with a sender and receiver, where packets are shunted in from one to the other in both directions.

        Getting started on this.

    3:21PM - Testing harness setup for endpoints. I should be able to implement an ack test now.

        Bringing across code from yojimbo for testing acks. See if this good, if not, write something new instead.

    3:52PM - Added a basic ack test with no packet loss. Passes.

        Next step is to add one with regular packet loss, eg. drop every 2nd packet, and make sure it comes up in the reported acks.

        Copying and pasting the test and doing this.

    3:57PM

        Nope. There is a bug in the ack system reported by the test on repeated reps. Digging in... it's missing ack #7 on the second run.

        Uninitialized data? Not possible. What could be causing it?!!!

    4:20PM - Logic error.

        I had something wrong in my code that was generating the sending ack. Added a separate variable and it's fixed. Was stepping up even # sequence # instead of all integers.

    4:36PM - Now there is a problem in the packet loss ack test.

        What's causing this? It looks like all packets are being acked, when every 2nd packet is dropped. What?

        Ahahah. Another logic error, was using wrong sequence buffer for ack generation. Using sent packets, instead of received packets. durrrrr.

    4:45PM - Got both tests working now. Taking a break.

        *** BREAK ***

    5:53PM - Next thing to do I think is to add counters to the endpoint. This way we can track things, it would also be good to unit test the counters.

        Adding counters now.

        Basic counters added. Adding some more for edge cases.

        Done.

    6:23PM - Adding some code to validate the config.

        Done.

        What's the next work that needs to be done?

        I can see that it should probably be the RTT estimates or packet loss over the connection, and possibly some research into the congestion avoidance method to see if it's applicable.

        Alternatively, I could move forward with the packet fragmentation and reassembly support.

        Hard to say what is the most important. If anything, it's probably the fragmentation and reassembly code, because this is the next most important key feature of this protocol.

        Doing that next then.

    6:39PM - Taking a break for dinner. Will continue with the packet fragmentation and reassembly tonight.

        *** BREAK ***





Monday May 1st, 2017
====================

    10:22AM - Starting work.

        Designing interface for endpoint. The main question basically is, do we use function pointers to send and process packets?

        I think the answer is yes. This is the easiest implementation for C and will integrate cleanly with C++. For other languages implementations, the decision of how to send packets can be different, for example, if it were a C++ implementation it would be a pure virtual method to be overridden or something like that.

        Either way, the standard part, which is the actual format of packets sent and received, is independent of this decision.

        Moving ahead with sketching out the interface.

    10:53AM - I have the reliable endpoint interface sketched out, short of the callbacks.

        Should the callbacks go in the config? Probably. It would be cleaner than having functions to set these callbacks.

        Adding this now.

    11:08AM - Added function pointers and a uint64_t "identifier" per-endpoint, which is passed to callbacks.

        For yojimbo on server, this would correspond to client index. 64bits allows the id to correspond to a pointer, or whatever else the user wants.

        Now moving ahead with implementation. Start with the packet send for now.

        Need to design the packet format. I think at minimum we need a prefix byte with flags.

        We have one flag that is definitely needed, which is fragment. This can be the low bit.

        If the bit is 1, then this is a fragment, and the rest of that start bit can be interpreted in a particular way (eg. fragment data in there)

        If the bit is 0, then this is a non-fragment, and perhaps we can stash some ack related stuff in the first byte, eg. a flag for perfect prediction.

        We could also stash congestion bits in the first byte, indicating that the other side thinks it is congested, or has detected bad network conditions.

        So don't worry too much about blowing a byte here, we can put useful information in there.

        Start with the byte being zero, meaning no flags, = regular packet, then follow this with the sequence, ack, ack bits data (w. no optimizations yet).

        Later on, we can try to do things like, derive the sequence # from the 64bit sequence sent from netcode.io, optimize for perfect ack bits etc.

        For now, just keep it simple!

    11:18AM - What is the first step here?

        Look at the yojimbo connection packet send and work out what needs to be done here.

    11:42AM - I have the send packet sketched out.

        Including the part up to calling the transmit packet function.

        To move forward I need to bring across netcode functions for reading and writing bytes, shorts, etc.

        Doing this now. Done.

        Now I can write the packet header.

        Done.

    11:52AM - Taking a lunch break.

        *** BREAK ***

     8:32PM - Time to implement the packet read.

        Packet read implemented. I think it's the correct call to have a process packet function pointer, because this way the process packet fn. can return false if it doesn't want a packet to be acked.

        Adding this now.

     9:41PM - Process packet function is working well.

        Next step is to add the array of acks that can be read by the user (but not via callback).

        Or alternatively, could provide a function callback on packet ack.

        Pros vs. cons? I think I like the ability to read off acks from an array better than a callback.

     9:45PM - Stop work for today.

        *** STOP WORK ***



Sunday April 30th, 2017
=======================

    8:30AM - Start work on reliable.io.

        This is the separation of the reliability system out of yojimbo, plus the addition of MTU fragmentation and reassembly.

        It is intended to make it possible to easily port to multiple languages, like C#, Golang, Rust etc.

        Its features will be:

            - pure c reference implementation

            - reliability system (eg. sequence, acks, ack bits)

            - an interface to get acks for packets via data structure, not callback (eg. get array of acks)

            - round trip time and packet loss estimates

            - BBR congestion avoidance (via notification, not immediate throttling)

                http://queue.acm.org/detail.cfm?id=3022184

                https://blog.acolyer.org/2017/03/31/bbr-congestion-based-congestion-control/

            - MTU packet fragmentation and reassembly

            - config struct that must be the same on both endpoints in order for the protocol to be compatible

    10:16AM - Sketched out basic project structure.

        This includes premake file, reliable.h, reliable.c, logging and asserts, test harness + setup git repo with gitignore.

        Moving forward now sketching out the config and endpoint structures.

        An endpoint is each side of the reliability system, eg. one on client, one on server per-client.

        Each endpoint must have the same configuration to be compatible, the configuration should be dynamic.

    10:30AM - Have the basic config and endpoint structures setup.

        What is the next step?

        I think it is to bring across the existing functionality from yojimbo for reliability system, commented out, so it can be used as reference.

        Actually, it's not this easy, as there are dependencies, plus the reliability system is yojimbo is spread across the connection system + message system.

        The best way would be to bring across dependencies first.

        These are:

            1. sequence buffer
            
            2. generate ack bits function

        I think netcode already has a sequence buffer port, so I can just bring that across and rename it.

        Nope. It doesn't. So this is basically the first step, port across the sequence buffer to "reliable_sequence_buffer" in C and test it.
        
        After this, port across generate ack bits to "reliable_generate_ack_bits" function.

    10:40AM - Taking a short break.

        *** BREAK ***

    11:23AM - Porting across the sequence buffer

        Going to be made a bit tricky by the fact that the sequence buffer is implemented in C++ with templates

        But I think as long as we know the stride of the sequence buffer entries, there should be no problem converting to C.

    12:04PM - Conversion continuing well.

        Sequence buffer functions ported across, stride based generic sequence buffer in C seems to be working well.

        Brought across supporting sequence functions.

        Rote converted from C++ to to.

    12:36PM - Finished converting sequence buffer to C.

        It's now ready to test.

        Converting unit test for sequence buffer.

    1:17PM - Finished converting across sequence buffer tests.

        *** BREAK ***

    4:33PM - What's the next step?

        Bringing across ack bits.

        Ack bits test passes.

    4:45PM - Break.

        *** BREAK ***

    5:23PM - Sketching out endpoint structure. What's it going to look like?

        I think it's mostly two sequence buffers (sent and received packets), the most recent sent sequence #, most recent received sequence #,
        plus some counters (these are very useful for testing and debugging...).

        Moving ahead with this.

    5:51PM - Basic structure for endpoint setup. 

        Implemented create and destroy for endpoint.

        Next I have to think for a while to decide on the interface for the endpoint.

        Fundamentally, I want to design it so that in the future I can reduce copies between it and netcode.io, in the common case.

        First, think of the user facing interface, it should present (in a version that copies), much like the interface for netcode.io, the user should be able to send packets and receive them, and it just looks normal. User should get sequence # of packets, but in this case sequence # should be 16 bit sequence # not 64bit.

        OK I can start from the outside in and design it this way. Later on, to improve performance, I can extend netcode.io and reliable.io interfaces so they have copy free versions.

    6:02PM - Taking a break.

        *** BREAK ***
